{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "source": [
        "!pip uninstall -y torch # Uninstall current torch version to avoid potential conflicts\n",
        "!pip install torch==2.0.1+cu118 --index-url https://download.pytorch.org/whl/cu118  # Reinstall specific torch version, specify CUDA version if needed\n",
        "!pip install vllm transformers"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHrEqhlrRgNP",
        "outputId": "69030c07-9c1f-46d5-e0db-42225323496b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.0.1+cu118\n",
            "Uninstalling torch-2.0.1+cu118:\n",
            "  Successfully uninstalled torch-2.0.1+cu118\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.1+cu118\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (15.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1+cu118) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\n",
            "Installing collected packages: torch\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import vllm\n",
        "import json\n",
        "import os\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoConfig, AutoTokenizer\n",
        "\n",
        "# --- Turing Tumble Hybrid Neuro-Symbolic AI ---\n",
        "\n",
        "# ... (Your existing code for imports, image upload, VLM caption extraction,\n",
        "# logic graph construction, PyTorch Geometric conversion, serialization,\n",
        "# LLM planning prompt, GNN model, and pipeline) ...\n",
        "\n",
        "\n",
        "# --- vLLM Integration with Hugging Face Model ---\n",
        "\n",
        "# Specify the Hugging Face model identifier\n",
        "model_name = \"google/flan-t5-xl\"  # Example: Replace with your desired model\n",
        "\n",
        "# Create the local model directory if it doesn't exist\n",
        "model_dir = \"model_cache\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Download and cache the model configuration and weights\n",
        "config = AutoConfig.from_pretrained(model_name, cache_dir=model_dir)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, config=config, cache_dir=model_dir)\n",
        "\n",
        "# Download and cache the tokenizer (if needed)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=model_dir)\n",
        "\n",
        "# Set the model path to the cached directory + config file\n",
        "# This assumes the config file name is config.json\n",
        "model_path = os.path.join(model_dir, \"config.json\")\n",
        "\n",
        "# Initialize vLLM with the model directory (model_dir) instead of the config file path\n",
        "llm = vllm.LLM(model=model_dir)\n",
        "\n",
        "\n",
        "# --- Modified plan_with_llm function ---\n",
        "\n",
        "def plan_with_llm(board_json):\n",
        "    prompt = generate_llm_prompt(board_json)\n",
        "\n",
        "    # Generate response using vLLM\n",
        "    outputs = llm.generate([prompt],\n",
        "                            sampling_params=vllm.SamplingParams(temperature=0.7, max_tokens=128))\n",
        "\n",
        "    # Extract the generated text\n",
        "    response_text = outputs[0].outputs[0].text\n",
        "\n",
        "    # Assuming the response is JSON, parse it\n",
        "    try:\n",
        "        return json.loads(response_text)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Warning: LLM response is not valid JSON. Returning empty action.\")\n",
        "        return {}  # Return an empty action if JSON parsing fails\n",
        "\n",
        "# ... (Rest of your code, including hybrid_pipeline and running the pipeline) ...\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "7ByIm_tVOPTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Turing Tumble Hybrid Neuro-Symbolic AI (Colab Notebook Version)\n",
        "\n",
        "# ------------------------\n",
        "# Install Dependencies (Colab only)\n",
        "# ------------------------\n",
        "!pip install -q transformers torch torchvision torch-geometric networkx openai Pillow\n",
        "!pip install -q openai\n",
        "# ------------------------\n",
        "# Imports\n",
        "# ------------------------\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from torch_geometric.data import Data as GNNData\n",
        "from torch_geometric.nn import GCNConv\n",
        "import networkx as nx\n",
        "from PIL import Image\n",
        "import json\n",
        "import openai\n",
        "import matplotlib.pyplot as plt\n",
        "import os # Import the os module\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "# Set your OpenAI API key using an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"  # Replace YOUR_API_KEY with your actual API key\n",
        "\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1\",\n",
        "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
        ")\n",
        "\n",
        "print(response.output_text)\n",
        "\n",
        "# ------------------------\n",
        "# Upload Image (Colab)\n",
        "# ------------------------\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# ------------------------\n",
        "# VLM Caption Extraction (BLIP)\n",
        "# ------------------------\n",
        "def extract_board_description_with_blip(image_path):\n",
        "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    inputs = processor(image, return_tensors=\"pt\")\n",
        "    out = model.generate(**inputs)\n",
        "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
        "    return caption\n",
        "\n",
        "# ------------------------\n",
        "# Dummy Logic Graph Construction\n",
        "# ------------------------\n",
        "def build_dummy_graph_from_caption(caption):\n",
        "    G = nx.DiGraph()\n",
        "    G.add_node(0, label=\"ball\", position=[0, 0])\n",
        "    G.add_node(1, label=\"ramp\", position=[1, 0], orientation=\"right\")\n",
        "    G.add_node(2, label=\"gear\", position=[2, 1])\n",
        "    G.add_edges_from([(0, 1), (1, 2)])\n",
        "    return G\n",
        "\n",
        "# ------------------------\n",
        "# Convert to PyTorch Geometric Format\n",
        "# ------------------------\n",
        "def convert_nx_to_gnn_data(graph):\n",
        "    node_labels = [ord(graph.nodes[n]['label'][0]) for n in graph.nodes()]\n",
        "    x = torch.tensor([[l] for l in node_labels], dtype=torch.float)\n",
        "    edge_index = torch.tensor(list(graph.edges())).t().contiguous()\n",
        "    return GNNData(x=x, edge_index=edge_index)\n",
        "\n",
        "# ------------------------\n",
        "# Serialize for LLM\n",
        "# ------------------------\n",
        "def serialize_board_to_json(graph):\n",
        "    nodes = []\n",
        "    for nid, attrs in graph.nodes(data=True):\n",
        "        nodes.append({\n",
        "            \"id\": nid,\n",
        "            \"type\": attrs.get(\"label\", \"unknown\"),\n",
        "            \"position\": attrs.get(\"position\", [0, 0]),\n",
        "            \"orientation\": attrs.get(\"orientation\", \"none\")\n",
        "        })\n",
        "    edges = [{\"from\": u, \"to\": v} for u, v in graph.edges()]\n",
        "    return {\n",
        "        \"nodes\": nodes,\n",
        "        \"connections\": edges,\n",
        "        \"marbles\": [],\n",
        "        \"gear_states\": [],\n",
        "        \"bit_states\": [],\n",
        "        \"goal\": \"Trigger final bit to ON using blue marble\"\n",
        "    }\n",
        "\n",
        "# ------------------------\n",
        "# LLM Planning Prompt\n",
        "# ------------------------\n",
        "def generate_llm_prompt(board_json):\n",
        "    return f\"\"\"\n",
        "You are an AI agent acting as a symbolic planner for a Turing Tumble puzzle.\n",
        "Your goal is: \\\"{board_json['goal']}\\\"\n",
        "\n",
        "Here is the current board state:\n",
        "{json.dumps(board_json, indent=2)}\n",
        "\n",
        "Reply with the best next action using this format:\n",
        "{{\n",
        "  \\\"action\\\": \\\"place_component\\\",\n",
        "  \\\"component\\\": \\\"ramp\\\",\n",
        "  \\\"position\\\": [4, 5],\n",
        "  \\\"orientation\\\": \\\"left\\\"\n",
        "}}\n",
        "\n",
        "Only use these actions:\n",
        "- \\\"place_component\\\"\n",
        "- \\\"remove_component\\\"\n",
        "- \\\"launch_marble\\\"\n",
        "\"\"\"\n",
        "\n",
        "def plan_with_llm(board_json):\n",
        "    prompt = generate_llm_prompt(board_json)\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return json.loads(response[\"choices\"][0][\"message\"][\"content\"])\n",
        "\n",
        "# ------------------------\n",
        "# Simple GNN Model\n",
        "# ------------------------\n",
        "class TuringTumbleGNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(1, 16)\n",
        "        self.conv2 = GCNConv(16, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "# ------------------------\n",
        "# Pipeline\n",
        "# ------------------------\n",
        "def hybrid_pipeline(image_path):\n",
        "    print(\"[1] Extracting board info with VLM...\")\n",
        "    caption = extract_board_description_with_blip(image_path)\n",
        "    print(\"\\n[Caption]:\", caption)\n",
        "\n",
        "    print(\"[2] Building logic graph from caption...\")\n",
        "    nx_graph = build_dummy_graph_from_caption(caption)\n",
        "\n",
        "    print(\"[3] Serializing for LLM planner...\")\n",
        "    board_json = serialize_board_to_json(nx_graph)\n",
        "\n",
        "    print(\"[4] Invoking LLM planner...\")\n",
        "    action = plan_with_llm(board_json)\n",
        "    print(\"\\n[LLM Suggested Action]:\", action)\n",
        "\n",
        "    print(\"[5] Symbolic reasoning with GNN...\")\n",
        "    gnn_data = convert_nx_to_gnn_data(nx_graph)\n",
        "    model = TuringTumbleGNN()\n",
        "    output = model(gnn_data)\n",
        "    print(\"\\n[GNN Output]:\", output)\n",
        "\n",
        "    return output, action\n",
        "\n",
        "# ------------------------\n",
        "# Run Pipeline\n",
        "# ------------------------\n",
        "output, action = hybrid_pipeline(image_path)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "xXQXUpUpOQI3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}