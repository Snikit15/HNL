{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976af4ec",
   "metadata": {},
   "source": [
    "# Turing Tumble Hybrid Neuro-Symbolic Agent\n",
    "This Colab notebook integrates image captioning, logic graph construction, and a simple GNN for solving Turing Tumble puzzles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0163a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers timm torch torchvision torchaudio\n",
    "!pip install git+https://github.com/suno-ai/BLIP.git\n",
    "!pip install torch-geometric -f https://data.pyg.org/whl/torch-$(python3 -c 'import torch; print(torch.__version__)').html\n",
    "!pip install networkx matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620804d",
   "metadata": {},
   "source": [
    "## Image Captioning using BLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcbaee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "# Load BLIP model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# Example image input (replace with Turing Tumble board image)\n",
    "img_url = 'https://example.com/turing_tumble_board.jpg'  # Replace with actual URL or upload\n",
    "image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
    "\n",
    "# Generate caption\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "out = model.generate(**inputs)\n",
    "caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "print(\"Caption:\", caption)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79864a92",
   "metadata": {},
   "source": [
    "## Logic Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample logic extracted from caption\n",
    "logic_statements = [\n",
    "    (\"start\", \"gear1\"),\n",
    "    (\"gear1\", \"gear2\"),\n",
    "    (\"gear2\", \"ball_drop\")\n",
    "]\n",
    "\n",
    "# Build graph\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(logic_statements)\n",
    "\n",
    "# Visualize graph\n",
    "plt.figure(figsize=(6, 4))\n",
    "nx.draw(G, with_labels=True, node_color='lightblue', edge_color='gray', node_size=2000, font_size=12)\n",
    "plt.title(\"Logic Graph\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630798ad",
   "metadata": {},
   "source": [
    "## Convert Logic Graph to PyG Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f97d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "# Map node names to indices\n",
    "node_to_idx = {node: i for i, node in enumerate(G.nodes())}\n",
    "edges = list(G.edges())\n",
    "edge_index = torch.tensor([[node_to_idx[src], node_to_idx[dst]] for src, dst in edges], dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Node features (dummy features here)\n",
    "x = torch.eye(len(G.nodes()))\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70199315",
   "metadata": {},
   "source": [
    "## Simple GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cfa7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = SimpleGNN(input_dim=data.num_node_features, hidden_dim=16, output_dim=2)\n",
    "output = model(data)\n",
    "print(\"GNN output:\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc491637",
   "metadata": {},
   "source": [
    "## Turing Tumble Puzzle Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement board state extraction and convert to graph\n",
    "print(\"Puzzle integration is currently placeholder. Add your board logic here.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
