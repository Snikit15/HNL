{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46ba162",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install necessary libraries\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q transformers\n",
    "!pip install -q torch-geometric\n",
    "!pip install -q networkx matplotlib\n",
    "!pip install -q git+https://github.com/salesforce/BLIP.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a902d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BLIP for VLM image understanding\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "\n",
    "def describe_board_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    inputs = processor(image, return_tensors=\"pt\").to(device)\n",
    "    caption_ids = blip_model.generate(**inputs)\n",
    "    return processor.decode(caption_ids[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e8916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load puzzle graph from JSON\n",
    "def load_graph_from_json(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        graph_json = json.load(f)\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    for node in graph_json[\"nodes\"]:\n",
    "        G.add_node(node[\"id\"], label=node.get(\"label\", \"\"))\n",
    "    for edge in graph_json[\"edges\"]:\n",
    "        G.add_edge(edge[\"source\"], edge[\"target\"])\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ab378",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graph_to_data(graph):\n",
    "    node_mapping = {node: i for i, node in enumerate(graph.nodes)}\n",
    "    features = []\n",
    "\n",
    "    for node in graph.nodes:\n",
    "        label = graph.nodes[node].get('label', '').lower()\n",
    "        feat = [\n",
    "            'ball' in label,\n",
    "            'bit' in label,\n",
    "            'gear' in label,\n",
    "            'interceptor' in label,\n",
    "            'crossover' in label,\n",
    "            'ramp' in label,\n",
    "            'toggle' in label,\n",
    "            'output' in label\n",
    "        ]\n",
    "        features.append(torch.tensor(feat, dtype=torch.float))\n",
    "\n",
    "    edge_index = []\n",
    "    for src, dst in graph.edges:\n",
    "        edge_index.append([node_mapping[src], node_mapping[dst]])\n",
    "\n",
    "    x = torch.stack(features)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    return Data(x=x, edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf2428",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SymbolicGNN(torch.nn.Module):\n",
    "    def __init__(self, in_features=8, hidden=32, out_features=8):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_features, hidden)\n",
    "        self.conv2 = GCNConv(hidden, out_features)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerPlanner:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "    def generate_plan(self, symbolic_output):\n",
    "        input_tokens = \" \".join([f\"{i}:{','.join(map(str, f.tolist()))}\" for i, f in enumerate(symbolic_output)])\n",
    "        inputs = self.tokenizer.encode(input_tokens, return_tensors=\"pt\")\n",
    "        outputs = self.model.generate(inputs, max_length=100, num_return_sequences=1)\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a7fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HybridPuzzleAgent:\n",
    "    def __init__(self):\n",
    "        self.gnn = SymbolicGNN()\n",
    "        self.planner = TransformerPlanner()\n",
    "\n",
    "    def solve(self, graph):\n",
    "        data = graph_to_data(graph)\n",
    "        symbolic_output = self.gnn(data.x, data.edge_index)\n",
    "        return self.planner.generate_plan(symbolic_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example run (replace paths with your own uploaded files)\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# Load graph\n",
    "# G = load_graph_from_json(\"puzzle08.json\")\n",
    "# agent = HybridPuzzleAgent()\n",
    "# plan = agent.solve(G)\n",
    "# print(\"Generated Plan:\", plan)\n",
    "# nx.draw(G, with_labels=True, node_color='lightgreen', edge_color='gray')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}